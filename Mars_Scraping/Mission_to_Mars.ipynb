{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a51d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import requests \n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a40922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\John\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d65ac3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the mars nasa new site\n",
    "url = 'https://redplanetscience.com'\n",
    "browser.visit(url)\n",
    "\n",
    "# Optional delay for loading page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d03899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the browser html to a soup object and then quit the browser\n",
    "html = browser.html\n",
    "news_soup = soup(html, 'html.parser')\n",
    "slide_elem = news_soup.select_one('div.list_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7387e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content_title\">NASA to Reveal Name of Its Next Mars Rover</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll want to assign the title and summary text to variables we'll reference later. \n",
    "# In the next empty cell, let's begin our scraping. Type the following:\n",
    "\n",
    "slide_elem.find('div', class_='content_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9584b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA to Reveal Name of Its Next Mars Rover'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the parent element to find the first `a` tag and save it as `news_title`\n",
    "news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although the code block above is similar to the last, there are some differences:\n",
    "# We have created a new variable for the title\n",
    "# Added the get_text() method\n",
    "# And we're searching within the parent element for the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we can update our code, we'll need to use our DevTools to make sure we're scraping the right tag and class.\n",
    "# Use the DevTools selector tool and select the article summary (teaser), then check to see which tag is highlighted.\n",
    "\n",
    "# We know that \"article_teaser_body\" is the right class name, but when we search for it, there is more than one result. \n",
    "#    What now?\n",
    "\n",
    "# That's okay. There will be many matches because there are many articles, each with a tag of <div /> and \n",
    "#  a class of article_teaser_body. We want to pull the first one on the list, not a specific one, \n",
    "#   so more than 10 results isfine. In this case, if our scraping code is too specific, \n",
    "#    we'd pull only that article summary instead of the most recent.\n",
    "\n",
    "# Because new articles are added to the top of the list, and we only need the most recent one, \n",
    "#   our search leads us to the first article. New news only, please!\n",
    "\n",
    "# There are two methods used to find tags and attributes with BeautifulSoup:\n",
    "#   .find() is used when we want only the first class and attribute we've specified.\n",
    "#   .find_all() is used when we want to retrieve all of the tags and attributes.\n",
    "# For example, if we were to use .find_all() instead of .find() when pulling the summary, \n",
    "#  we would retrieve all of the summaries on the page instead of just the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ec3c4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"After a months-long contest among students to name NASA's newest Mars rover, the agency will reveal the winning name — and the winning student — this Thursday. \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the parent element to find the paragraph text \n",
    "news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6de0b3",
   "metadata": {},
   "source": [
    "### Featured Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first image that pops up on the webpage is the featured image. Robin wants the full-size version of this image, \n",
    "#  so we know we'll want Splinter to click the \"Full Image\" button. From there, the page directs us to a slideshow. \n",
    "# It's a little closer to getting the full-size feature image, but we aren't quite there yet.\n",
    "\n",
    "# This is a lot of clicking to get to the image we want. Let's start getting our code ready to automate all of the clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1110f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL\n",
    "url = 'https://spaceimages-mars.com'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c6b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to click the full-size image button, we can go ahead and use the HTML tag in our code.\n",
    "\n",
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('button')[1]\n",
    "full_image_elem.click()\n",
    "\n",
    "# Notice the indexing chained at the end of the first line of code? \n",
    "# With this, we've stipulated that we want our browser to click the second button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to click the More Info button to get to the next page. \n",
    "# Let's look at the DevTools again to see what elements we can use for our scraping.\n",
    "\n",
    "# With the new page loaded onto our automated browser, it needs to be parsed so we can continue and scrape the \n",
    "#  full-size image URL. In the next empty cell, type the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfd2c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aeddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to find the relative image URL. In our browser (make sure you're on the same page as the automated one), \n",
    "# activate your DevTools again. This time, let's find the image link for that image. This is a little more tricky.\n",
    "# Remember, Robin wants to pull the most recently posted image for her web app. \n",
    "\n",
    "# It's important to note that the value of the src will be different every time the page is updated, \n",
    "#  so we can't simply record the current value—we would only pull that image each time the code is executed, \n",
    "#   instead of the most recent one.\n",
    "\n",
    "# We'll use the image tag and class (<img />and fancybox-img) to build the URL to the full-size image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d4ecd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the relative image url\n",
    "img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "img_url_rel\n",
    "\n",
    "# We've done a lot with that single line.\n",
    "\n",
    "# Let's break it down:\n",
    "#   An img tag is nested within this HTML, so we've included it.\n",
    "#   .get('src') pulls the link to the image.\n",
    "# What we've done here is tell BeautifulSoup to look inside the <img /> tag for an image with a class of fancybox-image. \n",
    "# Basically we're saying, \"This is where the image we want lives—use the link that's inside these tags.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c3c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spaceimages-mars.com/image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add the base URL to our code.\n",
    "\n",
    "# Use the base URL to create an absolute URL\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a86a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using an f-string for this print statement because it's a cleaner way to create print statements; \n",
    "#  they're also evaluated at run-time. This means that it, and the variable it holds, doesn't exist until the code is \n",
    "#   executed and the values are not constant. This works well for our scraping app because the data we're scraping is live \n",
    "#    and will be updated frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d24af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robin has chosen to collect her data from Mars Facts (https://galaxyfacts-mars.com/), so let's visit the webpage to \n",
    "#  look at what we'll be working with. Robin already has a great photo and an article, so all she wants from this page is \n",
    "#   the table. Her plan is to display it as a table on her own web app, so keeping the current HTML table format is important.\n",
    "\n",
    "# Let's look at the webpage again, this time using our DevTools. All of the data we want is in a <table /> tag. HTML code\n",
    "#   used to create a table looks fairly complex, but it's really just breaking down and naming each component.\n",
    "\n",
    "# Tables in HTML are basically made up of many smaller containers. The main container is the <table /> tag. \n",
    "# Inside the table is <tbody />, which is the body of the table—the headers, columns, and rows.\n",
    "\n",
    "# <tr /> is the tag for each table row. Within that tag, the table data is stored in <td /> tags. \n",
    "# This is where the columns are established."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of scraping each row, or the data in each <td />, we're going to scrape the entire table with \n",
    "#   Pandas' .read_html() function.\n",
    "\n",
    "# At the top of your Jupyter Notebook, add import pandas as pd to the dependencies and rerun the cell. \n",
    "# This way, we'll be able to use this new function without generating an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923ac657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars</th>\n",
       "      <th>Earth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <td>Mars</td>\n",
       "      <td>Earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter:</th>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance from Sun:</th>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length of Year:</th>\n",
       "      <td>687 Earth days</td>\n",
       "      <td>365.24 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature:</th>\n",
       "      <td>-87 to -5 °C</td>\n",
       "      <td>-88 to 58°C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Mars            Earth\n",
       "description                                              \n",
       "Mars - Earth Comparison             Mars            Earth\n",
       "Diameter:                       6,779 km        12,742 km\n",
       "Mass:                    6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "Moons:                                 2                1\n",
       "Distance from Sun:        227,943,824 km   149,598,262 km\n",
       "Length of Year:           687 Earth days      365.24 days\n",
       "Temperature:                -87 to -5 °C      -88 to 58°C"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "df.columns=['description', 'Mars', 'Earth']\n",
    "df.set_index('description', inplace=True)\n",
    "df\n",
    "\n",
    "\n",
    "# Now let's break it down:\n",
    "\n",
    "# df = pd.read_htmldf = pd.read_html('https://galaxyfacts-mars.com')[0] With this line, we're creating a new DataFrame \n",
    "#  from the HTML table. The Pandas function read_html() specifically searches for and returns a list of tables found\n",
    "#   in the HTML. By specifying an index of 0, we're telling Pandas to pull only the first table it encounters,\n",
    "#    or the first item in the list. Then, it turns the table into a DataFrame.\n",
    "\n",
    "# df.columns=['description', 'Mars', 'Earth'] Here, we assign columns to the new DataFrame for additional clarity.\n",
    "\n",
    "# df.set_index('description', inplace=True) By using the .set_index() function, we're turning the Description column into \n",
    "#  the DataFrame's index. inplace=True means that the updated index will remain in place, without having to reassign the \n",
    "#   DataFrame to a new variable.\n",
    "\n",
    "# Now, when we call the DataFrame, we're presented with a tidy, Pandas-friendly representation of the HTML table we were \n",
    "#  just viewing on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3a014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars</th>\\n      <th>Earth</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Mars - Earth Comparison</th>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>Diameter:</th>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>Distance from Sun:</th>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>Length of Year:</th>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we add the DataFrame to a web application? Robin's web app is going to be an actual webpage. \n",
    "# Our data is live—if the table is updated, then we want that change to appear in Robin's app also.\n",
    "\n",
    "# Thankfully, Pandas also has a way to easily convert our DataFrame back into HTML-ready code using \n",
    "#   the .to_html() function. Add this line to the next cell in your notebook and then run the code.\n",
    "\n",
    "df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is a slightly confusing-looking set of HTML code—it's a <table /> element with a lot of nested elements.\n",
    "# This means success. After adding this exact block of code to Robin's web app, the data it's storing will be presented\n",
    "#   in an easy-to-read tabular format.\n",
    "\n",
    "# Now that we've gathered everything on Robin's list, we can end the automated browsing session.\n",
    "# This is an important line to add to our web app also. \n",
    "# Without it, the automated browser won't know to shut down—it will continue to listen for instructions and \n",
    "#  use the computer's resources (it may put a strain on memory or a laptop's battery if left on). \n",
    "# We really only want the automated browser to remain active while we're scraping data. \n",
    "# It's like turning off a light switch when you're ready to leave the room or home.\n",
    "\n",
    "# In the last empty cell of Jupyter Notebook, add browser.quit() and execute that cell to end the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b13b6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad793b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
